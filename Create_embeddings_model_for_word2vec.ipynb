{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Create embeddings model for word2vec.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OmarMeriwani/CE807-Sentiment-analysis/blob/master/Create_embeddings_model_for_word2vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "JBxdUnzvVDb6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This file contains the code for creating word embeddings for word2vec model"
      ]
    },
    {
      "metadata": {
        "id": "suzYSLOGVC7D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from string import punctuation\n",
        "from gensim.models import Word2Vec\n",
        "import pandas as pd\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "28LqIhajVEX_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "A method used for loading files and getting text from them."
      ]
    },
    {
      "metadata": {
        "id": "IJCdic1DVaKZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_doc(filename):\n",
        "\tfile = open(filename, 'r')\n",
        "\ttext = file.read()\n",
        "\tfile.close()\n",
        "\treturn text\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D_UtEVODVaQ4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Tokenize, remove punctuation and add words that exist in the vocabulary."
      ]
    },
    {
      "metadata": {
        "id": "hJazIDRFVaZG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def doc_to_clean_lines(doc, vocab):\n",
        "\tclean_lines = list()\n",
        "\tlines = doc.splitlines()\n",
        "\tfor line in lines:\n",
        "\t\ttokens = line.split()\n",
        "\t\ttable = str.maketrans('', '', punctuation)\n",
        "\t\ttokens = [w.translate(table) for w in tokens]\n",
        "\t\ttokens = [w for w in tokens if w in vocab]\n",
        "\t\tclean_lines.append(tokens)\n",
        "    return clean_lines\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xJVNUFqmVafa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Read either full sentences or all phrases, and store the result into line separated sentences"
      ]
    },
    {
      "metadata": {
        "id": "w1AM1FEpVsaP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def readfile(filename):\n",
        "\tdf = pd.read_csv(filename,header=0,sep='\\t')\n",
        "\tmode = 'sentence' #all sentences or only full reviews (sentence,full)\n",
        "\tdata = ''\n",
        "\tprev = ''\n",
        "\tfor i in range(0,len(df)):\n",
        "\t\tif mode == 'sentence':\n",
        "\t\t\tif prev != str(df.loc[i][1]):\n",
        "\t\t\t\tsentence = df.loc[i][2]\n",
        "\t\t\t\tprev = str(df.loc[i][1])\n",
        "\t\t\telse:\n",
        "\t\t\t\tcontinue\n",
        "\t\telse:\n",
        "\t\t\tsentence = df.loc[i][2]\n",
        "\t\treviewPolarity = int(df.loc[i][3])\n",
        "\t\tdata += '\\n' + (sentence)\n",
        "\treturn data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mobgduWoVsg6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Read file, clean it and return it as a list of lines"
      ]
    },
    {
      "metadata": {
        "id": "wpBkYOZQV4ul",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def process_docs2(directory, vocab):\n",
        "\tlines = list()\n",
        "\tdoc = readfile(directory)\n",
        "\tdoc_lines = doc_to_clean_lines(doc, vocab)\n",
        "\tlines += doc_lines\n",
        "\treturn lines\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4wtaH9NwV40U",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Load the vocabulary"
      ]
    },
    {
      "metadata": {
        "id": "nVwgfH-gWCI4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vocab_filename = 'vocabulary.txt'\n",
        "vocab = load_doc(vocab_filename)\n",
        "vocab = vocab.split()\n",
        "vocab = set(vocab)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tysXrgrAWCPj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Read the training dataset."
      ]
    },
    {
      "metadata": {
        "id": "8HV5LMUJWIbo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "docs = process_docs2('train.csv',vocab)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vlApP3TdWIkO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create embedding model."
      ]
    },
    {
      "metadata": {
        "id": "YSuLdcKpVDlb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sentences =  docs\n",
        "model = Word2Vec(sentences, window=5, workers=8, min_count=1)\n",
        "words = list(model.wv.vocab)\n",
        "filename = 'embedding2.txt'\n",
        "model.wv.save_word2vec_format(filename, binary=False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}